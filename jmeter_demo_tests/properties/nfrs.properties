###############################
#Name: For identification in the report file (will appear in the classname attribute).
###############################

###############################
#Metric: Defines the aggregate to be calculated of all samples. Supported values:
#Other, custom metrics can be defined by implementing the interface Metric and specifying the fully-qualified class name in the Metric column.
#If the Metric is empty or invalid the KPI will be skipped.
#MEAN, AVERAGE, μ	Average response time (arithmetic mean)
#SD, σ	Standard Deviation of response times (population/non-bias corrected)
#Pn	n-th percentile response time (e.g. P90). One of two different algorithms is used for percentile calcuations: A more accurate one for smaller sample sets and an estimate for larger sample sets.
#MAX	Maximum response time
#MIN	Minimum response time
#HITS, SAMPLES	Total number of samples (requests)
#ERRORS	Error rate, fraction of unsuccessful samples (between 0 and 1)
################################

###############################
#Label (Regex): Regular expression defining what samples to include in calculation. An empty Label column matches all samples (equivalent to .*). The sample name must fully match the expression to be included.
#Web_.*	
#App_.*	
#	.*
################################

###############################
#Comparator: What operation to use for comparing the (actual) measured value with the (expected) threshold. 
#Supported values: < (default), <=, >, >=.
################################

###############################
#Threshold: Upper or lower bound that the value must not exceed. Decimal number. Unit is milliseconds for response time metrics. KPI will be skipped if threshold is undefined or invalid.
#Calculate Against Rate per second as an average across the test 
#${__groovy( (${__P(DURATION)} as int) *   (${__P(HOMEPAGE_HITS_PER_SECOND_THRESHOLD)} as float)      )}
################################

A_NAME=ERROR_RATE
A_METRIC=ERRORS
A_LABEL=.*
A_COMPARATOR=<=
A_THRESHOLD=0

B_NAME=
B_METRIC=
B_LABEL=
B_COMPARATOR=<=
B_THRESHOLD=

C_NAME=
C_METRIC=
C_LABEL=
C_COMPARATOR=<=
C_THRESHOLD=
